## English

What is AI, how do apps like ChatGPT work and why are there concerns?
What is AI, how does it work and why are some people concerned about it?

Close-up of a woman wearing a bright yellow jumper holding a smartphone.Image source, Getty Images
Updated 29 July 2025
Artificial intelligence (AI) has increasingly become part of everyday life over the past decade.
It is being used to personalise social media feeds, spot friends and family in smartphone photos and pave the way for medical breakthroughs.
But the rise of chatbots like OpenAI's ChatGPT and Meta AI has been accompanied by concern about the technology's environmental impact, ethical implications and data use.
What is AI and what is it used for?

AI allows computers to process large amounts of data, identify patterns and follow detailed instructions about what to do with that information.
Computers cannot think, empathise or reason.
However, scientists have developed systems that can perform tasks which usually require human intelligence, trying to replicate how people acquire and use knowledge.
Media caption,
Watch: What is artificial intelligence?
This could be trying to anticipate what product an online shopper might buy, based on previous purchases, in order to recommend items.
The technology is also behind voice-controlled virtual assistants like Apple's Siri and Amazon's Alexa, and is being used to develop systems for self-driving cars.
AI also helps social platforms like Facebook, TikTok and X decide what posts to show users. Streaming services Spotify and Deezer use AI to suggest music.
There are also a number of applications in medicine, as scientists use AI to help spot cancers, review X-ray results, speed up diagnoses and identify new treatments.
A simple guide to help you understand AI
Five things you really need to know about AI
Generative AI is used to create new content which can seem like it has been made by a human.
It does this by learning from vast quantities of existing data such as online text and images.
ChatGPT and Chinese rival DeepSeek's chatbot are popular generative AI tools that can be used to produce text, images, code and more material.
Google's Gemini or Meta AI can similarly hold text conversations with users.
Apps like Midjourney or Veo 3 are dedicated to creating images or video from simple text prompts.
A smartphone displays four AI-generated images, underneath a prompt which reads: "Make an artistic portrait of a flying cat". The logo for xAI is shown in the background.
Image source, Getty Images
Image caption,
Elon Musk's generative AI chatbot Grok can also generate images for users who pay for X (formerly Twitter).
Generative AI can also be used to make high-quality music.
Songs mimicking the style or sound of famous musicians have gone viral, sometimes leaving fans confused about their authenticity.
Why is AI controversial?

While acknowledging AI's potential, some experts are worried about the implications of its rapid growth.
The International Monetary Fund (IMF) has warned AI could affect nearly 40% of jobs, and worsen global financial inequality.
Prof Geoffrey Hinton, a computer scientist regarded as one of the "godfathers" of AI development, has expressed concern that powerful AI systems could even make humans extinct - although his fear was dismissed by his fellow "AI godfather", Yann LeCun.
Critics also highlight the tech's potential to reproduce biased information, or discriminate against some social groups.
This is because much of the data used to train AI comes from public material, including social media posts or comments, which can reflect existing societal biases such as sexism or racism.
Facebook apology as AI labels black men 'primates'
Twitter finds racial bias in image-cropping AI
And while AI programmes are growing more adept, they are still prone to errors - such as creating images of people with the wrong number of fingers or limbs.
Generative AI systems are known for their ability to "hallucinate" and assert falsehoods as fact, even sometimes inventing sources for the inaccurate information.
Apple halted a new AI feature in January after it incorrectly summarised news app notifications.
The BBC complained about the feature after Apple's AI falsely told readers that Luigi Mangione - the man accused of killing UnitedHealthcare CEO Brian Thompson - had shot himself.
Google has also faced criticism over inaccurate answers produced by its AI search overviews.
Google launches new AI search feature in UK
This has added to concerns about the use of AI in schools and workplaces, where it is increasingly used to help summarise texts, write emails or essays and solve bugs in code.
There are worries about students using AI technology to "cheat" on assignments, or employees "smuggling" it into work.
'I'm being paid to fix issues caused by AI'
Billie Eilish, wearing a black suit and white shirt, holding her Oscar award at the 2024 Vanity Fair Oscar After Party
Image source, Getty Images
Image caption,
Billie Eilish was among 200 artists who called for an end to "predatory" use of AI in music in an open letter.
Writers, musicians and artists have also pushed back against the technology on ethical grounds, accusing AI developers of using their work to train systems without consent or compensation.
Thousands of creators - including Abba singer-songwriter Björn Ulvaeus, writers Ian Rankin and Joanne Harris and actress Julianne Moore - signed a statement, external in October 2024 calling AI a "major, unjust threat" to their livelihoods.
Billie Eilish and Nicki Minaj want stop to 'predatory' music AI
AI-written book shows why the tech 'terrifies' creatives
How does AI effect the environment?

It is not clear how much energy AI systems use, but some researchers estimate the industry as a whole could soon consume as much as the Netherlands.
Creating the powerful computer chips needed to run AI programmes requires lots of power and water.
Demand for generative AI services has also meant an increase in the number of data centres which power them.
These huge halls - housing thousands of racks of computer servers - use substantial amounts of energy and require large volumes of water to keep them cool.
Some large tech companies have invested in ways to reduce or reuse the water needed, or have opted for alternative methods such as air-cooling.
However, some experts and activists fear that AI will worsen water supply problems.
Media caption,
Watch: Beverley Morris flushes her toilet using a bucket because of low water pressure
The BBC was told in February that government plans to make the UK a "world leader" in AI could put already stretched supplies of drinking water under strain.
In September 2024, Google said it would reconsider proposals for a data centre in Chile, which has struggled with drought.
Electricity grids creak as AI demands soar
Are there laws governing AI?

Some governments have already introduced rules governing how AI operates.
The EU's Artificial Intelligence Act places controls on high risk systems used in areas such as education, healthcare, law enforcement or elections. It bans some AI use altogether.
Generative AI developers in China are required to safeguard citizens' data, and promote transparency and accuracy of information. But they are also bound by the country's strict censorship laws.
In the UK, Prime Minister Sir Keir Starmer has said the government "will test and understand AI before we regulate it".
Both the UK and US have AI Safety Institutes that aim to identify risks and evaluate advanced AI models.
In 2024 the two countries signed an agreement to collaborate on developing "robust" AI testing methods.
However, in February 2025, neither country signed an international AI declaration which pledged an open, inclusive and sustainable approach to the technology.
Several countries including the UK are also clamping down on use of AI systems to create deepfake nude imagery and child sexual abuse material.
Man who made 'depraved' child images with AI jailed
Inside the deepfake porn crisis engulfing Korean schools
A green promotional banner with black squares and rectangles forming pixels, moving in from the right. The text says: “Tech Decoded: The world’s biggest tech news in your inbox every Monday.”

## 中文

### 人工智能（AI）究竟是何方神圣？一文读懂它的是与非

过去十年，人工智能（AI）已悄然渗透到我们日常生活的角角落落。

从社交媒体为你量身定制的信息流，到智能手机相册里帮你圈出的亲朋好友，再到为医学突破铺平道路的科研工具，它的身影无处不在。

然而，随着ChatGPT、Meta AI等聊天机器人的异军突起，关于这项技术的环境代价、伦理争议和数据安全等问题，也开始甚嚣尘上。

那么，人工智能究竟是何方神圣？它如何运作？人们的担忧又从何而来？

#### AI是什么？它能做什么？

说白了，人工智能就是让计算机能够处理海量数据，从中找出规律，然后根据详细指令来执行任务。

计算机本身无法思考、共情或推理。但科学家们开发出了一套系统，能够模仿人类获取和运用知识的方式，去执行那些通常需要人类智慧才能完成的任务。

打个比方，AI可以根据你过往的购物记录，预测你接下来可能会买什么，然后为你精准推荐商品。我们日常使用的语音助手，如苹果的Siri和亚马逊的Alexa，背后也是AI在驱动。它同样是无人驾驶汽车技术的核心。

此外，AI也在塑造着我们的信息世界。Facebook、TikTok和X（原推特）等社交平台，依靠AI来决定向你展示哪些内容；Spotify等流媒体服务，则利用AI为你推荐音乐。

在医疗领域，AI的应用更是大有可为。科学家正利用它来辅助诊断癌症、解读X光片、加快诊疗速度，甚至发现新的治疗方法。

而当下最火热的，当属**生成式人工智能（Generative AI）**。

顾名思义，它能“生成”全新的内容，其成果足以以假乱真，仿佛出自人类之手。它通过学习海量的现有数据（例如网上的文本和图片）来实现这一点。

OpenAI旗下的ChatGPT和来自中国的DeepSeek等，都是热门的生成式AI工具，能够生成文本、图片、代码等各种材料。谷歌的Gemini或Meta AI也能与用户进行流畅的文本对话。而像Midjourney或Veo 3这样的应用，则专注于根据简单的文字指令，创造出令人惊叹的图像和视频。

生成式AI甚至还能创作出高品质的音乐。那些模仿著名音乐人风格的歌曲在网上疯传，有时甚至让粉丝都难辨真伪。

#### AI为何会引发巨大争议？

在承认AI巨大潜力的同时，许多专家也对其飞速发展所带来的影响深感忧虑。

*   **饭碗与公平问题**：国际货币基金组织（IMF）曾发出警告，AI可能会冲击全球近40%的就业岗位，并加剧全球贫富差距。
*   **生存与安全问题**：被誉为“AI教父”之一的计算机科学家杰弗里·辛顿（Geoffrey Hinton）教授甚至表示，强大的AI系统最终可能导致人类灭绝——尽管他的“教父”同事杨立昆（Yann LeCun）对此不以为然。
*   **偏见与歧视问题**：批评者还指出，AI可能会复制甚至放大偏见。这是因为训练AI的大部分数据来源于公共领域，其中充斥着现实社会中已有的性别或种族歧视。
*   **“一本正经地胡说八道”**：尽管AI程序日益强大，但它们仍会犯错。生成式AI以其“幻觉”（hallucinate）能力而闻名，它们会把谬误当作事实来陈述，甚至为错误信息编造信源。今年1月，苹果公司就因其AI功能错误地总结新闻通知而紧急叫停了该功能。谷歌也因其AI搜索摘要给出的不准确答案而备受诟病。
*   **教育与工作的“灰色地带”**：AI在校园和职场的普及，也带来了新的担忧。学生是否会用AI来写作业“作弊”？员工是否会“偷偷”用它来完成工作？这些都成了棘手的问题。
*   **创作与伦理的冲突**：作家、音乐家和艺术家们也纷纷站出来，从伦理角度对这项技术提出抗议，指责AI开发者在未经他们同意、也未支付报酬的情况下，就用他们的作品来训练系统。2024年10月，包括ABBA乐队成员比约恩·奥瓦尔斯（Björn Ulvaeus）、作家伊恩·兰金（Ian Rankin）在内的数千名创作者签署了一份联合声明，称AI对其生计构成了“重大且不公的威胁”。

#### AI对环境有何影响？

AI系统的具体能耗尚不明确，但一些研究人员估计，整个行业的耗电量可能很快就会与荷兰一个国家相当。

运行AI程序所需的强大计算机芯片，其制造过程本身就需要消耗大量电力和水资源。而生成式AI服务的需求激增，意味着为它们提供动力的数据中心数量也在不断增加。这些巨大的机房容纳着成千上万的服务器机架，不仅耗能巨大，还需要大量的水来进行冷却。

一些科技巨头已投资于减少或再利用水资源的方法，但仍有专家和活动人士担心，AI的蓬勃发展将会加剧全球的水资源供应问题。

#### 法律跟上脚步了吗？

面对AI这匹脱缰的野马，一些政府已经开始着手制定规则。

*   **欧盟（EU）**的《人工智能法案》对教育、医疗、执法等高风险领域的AI系统进行了严格管控，并完全禁止了某些AI应用。
*   **中国**要求生成式AI开发者必须保障公民数据安全，并确保信息的透明与准确，同时也要遵守严格的审查法规。
*   **英国**首相基尔·斯塔默（Keir Starmer）爵士则表示，政府将“先测试和理解AI，然后再进行监管”。英国和**美国**都成立了AI安全研究所，旨在识别风险并评估先进的AI模型。

然而，在2025年2月，英美两国均未签署一项旨在推动AI技术开放、包容和可持续发展的国际宣言。

与此同时，包括英国在内的多个国家，正在严厉打击利用AI系统制作深度伪造的裸体图像和儿童性虐待材料。

这场围绕AI的全球博弈，才刚刚拉开序幕。

